# -*- coding: utf-8 -*-
"""SVM-Assignment4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R-uDd4wt_dDiSiSMxVZ-N6qUomIBaTTS
"""

import pandas as pd
import numpy as np
from google.colab import files
from sklearn import svm
from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

upload = files.upload()

data_test = pd.read_csv('hw4Test.csv')
data_train = pd.read_csv('hw4Train.csv')
data_iris = pd.read_csv('iris.csv')

data_iris.head()

data_train['class'].replace(['Iris-versicolor', 'Iris-virginica'], [0, 1], inplace=True)  #Changing class labels to numeric
data_test['class'].replace(['Iris-versicolor', 'Iris-virginica'], [0, 1], inplace=True)   #Changing class labels to numeric
features = ["Sepal Length","Petal Length"]  
target = ["class"]

def svmlinear(trainX, trainY, testX, testY, penalty):  #Linear kernel SVM
  clf = svm.SVC(C = penalty, kernel="linear") 

  clf.fit(trainX, trainY)
  y_pred = clf.predict(testX)

  print("Linear SVM Accuracy:",metrics.accuracy_score( testY, y_pred))
  

def svmrbf(trainX, trainY, testX, testY, penalty):  #Radial Basis Function kernel SVM
  clf = svm.SVC(C = penalty, kernel="rbf") 

  clf.fit(trainX, trainY)
  y_pred = clf.predict(testX)

  print("RBF SVM Accuracy:",metrics.accuracy_score( testY, y_pred))
  

def svmpoly(trainX, trainY, testX, testY, penalty): #Polynomial kernel SVM
  clf = svm.SVC(C = penalty, kernel="poly", degree=2) 

  clf.fit(trainX, trainY)
  y_pred = clf.predict(testX)

  print("Polynomial SVM Accuracy:",metrics.accuracy_score( testY, y_pred))
  #classification_report



penalty = [0.001, 1, 1000]
for i in penalty:
  print("For Penalty: ",i)
  svmlinear(data_train[features], data_train[target],data_test[features], data_test[target], i)
  svmrbf(data_train[features], data_train[target],data_test[features], data_test[target], i)
  svmpoly(data_train[features], data_train[target],data_test[features], data_test[target], i)
  print("-----------------------------------------")

|data_iris.head()

data_iris['Iris Class'].unique()

data_iris['Iris Class'].replace(['Iris-versicolor', 'Iris-virginica', 'Iris-setosa'], [0,1,2], inplace=True)
iris_features_before_selection = ["Sepal Length", "Sepal Width", "Petal Length","Petal Width"]
iris_features_after_selection = ["Petal Length","Petal Width"]
iris_target = ["Iris Class"]

"""**This section is for comparing two sets after applying feature selection**"""

irisx_train, irisx_test, irisy_train, irisy_test = train_test_split(data_iris[iris_features_after_selection], data_iris[iris_target], test_size = .10, random_state = 25)
before_irisx_train, before_irisx_test, before_irisy_train, before_irisy_test = train_test_split(data_iris[iris_features_before_selection], data_iris[iris_target], test_size = .10, random_state = 25)

for i in penalty:
  print("For Penalty: ",i)
  svmlinear(irisx_train, irisy_train,irisx_test, irisy_test, i)
  svmrbf(irisx_train, irisy_train,irisx_test, irisy_test, i)
  svmpoly(irisx_train, irisy_train,irisx_test, irisy_test, i)
  print("-----------------------------------------")

for i in penalty:
  print("For Penalty: ",i)
  svmlinear(before_irisx_train, before_irisy_train,before_irisx_test, before_irisy_test, i)
  svmrbf(before_irisx_train, before_irisy_train, before_irisx_test, before_irisy_test, i)
  svmpoly(before_irisx_train, before_irisy_train,before_irisx_test, before_irisy_test, i)
  print("-----------------------------------------")

