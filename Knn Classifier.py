# -*- coding: utf-8 -*-
"""Knn Classifier-Assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZXZSEMv5-YCiJ0Ay2MctIZZtGnrueuKM

**1.1**
"""

import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
from google.colab import files
import pandas as pd
from scipy.stats import mode

test = files.upload()

test_df = pd.read_csv('test.csv')
train_df = pd.read_csv('train.csv')
#test = test_df.values.tolist()
#train = train_df.values.tolist()

train_df.head()

def confusion_mat(actual, predicted):
  confusion_matrix = pd.crosstab(actual['label'], predicted[0], rownames=['Actual'], colnames=['Predicted'])
  print(confusion_matrix)


def get_eucleadian_distance(p1,p2):
  euclidean_dist = np.sqrt(np.sum(p1 - p2)**2) #Eucledian Distance
  return euclidean_dist

def new_manhattan_distance(p1, p2): #manhattan Distance

  dist = 0
  for i in range(len(p1)):
    dist = dist + abs(p1[i] - p2[i])
    manhattan_dist = dist

  return manhattan_dist

def Chebyshev(p1,p2):
  chebyshev = np.abs(p1-p2).max() #Chevishev distance https://people.revoledu.com/kardi/tutorial/Similarity/ChebyshevDistance.html
  return chebyshev


#get_eucleadian_distance(test_df.iloc[1][:7],test_df.iloc[2][:7])
def votes(distances, y_train,k):

  distance_data = pd.DataFrame(data=distances, columns=['Distance List'], index=y_train.index) 
  knlst = distance_data.sort_values(by=['Distance List'], axis=0)[:k] #Sorting the distance data based on distance values for voting
  labels = y_train.loc[knlst.index]
  votes = mode(labels).mode[0] #taking the labels with most votes. The votes are based on distance measures to closest datapoints

  return votes


def knnclassifier(x_train,x_test,y_train,y_test,k, measure):
  y_pred = []

  for i in x_test.to_numpy(): #For all the datapoints we iterate over the dataset
    distances = []

    for j in range(len(x_train)): #For all of the datapoints, we measure distance of it from all the other datapoints in the dataset

      if measure == 1:
        distance = get_eucleadian_distance(np.array(x_train.iloc[j]),i) 
      elif measure ==2:
        distance = new_manhattan_distance(np.array(x_train.iloc[j]),i)
      elif measure==3:
        distance = Chebyshev(np.array(x_train.iloc[j]),i)
      
      distances.append(distance)  
    
    
    voting = votes(distances, y_train, k) #We vote for the best class assignment based on the votes.
    y_pred.append(voting)

  return y_pred

x_train = train_df.loc[:,'1':'7']
y_train = train_df.loc[:,'label']
x_test = test_df.loc[:,'1':'7']
y_test = test_df.loc[:,'label']

dist_measures = [1,2,3]
k = [1, 5, 9, 15]

for j in k:
  print("For k = ", j)
  for i in dist_measures:
    y_pred = knnclassifier(x_train,x_test,y_train,y_test,j, i)
    if i==1:
      print(f"Accuracy for Eucledian Distance: {sum(y_pred == y_test) / y_test.shape[0]*100}%")
    elif i==2:
      print(f"Accuracy for Manhattan Distance: {sum(y_pred == y_test) / y_test.shape[0]*100}%")
    elif i==3:
      print(f"Accuracy for Chevishev Distance: {sum(y_pred == y_test) / y_test.shape[0]*100}%")

    print("Confusion Matrix")    
    predicted = pd.DataFrame(y_pred)
    actual = pd.DataFrame(y_test)
    confusion_mat(actual, predicted)
    print("==================================")



def get_eucleadian_distance(p1,p2):
  euclidean_dist = np.sqrt(np.sum(p1 - p2)**2)
  return euclidean_dist

def new_euclidean_distance(p1, p2):

  dist = 0
  for i in range(len(p1)):
    dist = dist + (p1[i] - p2[i])**2

  euclidean_dist = np.sqrt(dist)
  #print(euclidean_dist)
  return euclidean_dist

def new_manhattan_distance(p1, p2):

  dist = 0

  for i in range(len(p1)):
    dist = dist + abs(p1[i] - p2[i])

    manhattan_dist = dist

  return manhattan_dist
#get_eucleadian_distance(test_df.iloc[1][:7],test_df.iloc[2][:7])
def votes(distances, y_train,k):

  distance_data = pd.DataFrame(data=distances, columns=['Distance List'], index=y_train.index)
  knlst = distance_data.sort_values(by=['Distance List'], axis=0)[:k] 
  labels = y_train.loc[knlst.index]
  votes = mode(labels).mode[0]

  return votes


def knnclassifier(x_train,x_test,y_train,y_test,k):
  y_pred = []

  for i in x_test.to_numpy():
    distances = []
    for j in range(len(x_train)):
      #distance = get_eucleadian_distance(np.array(x_train.iloc[j]),i)
      #distance = new_euclidean_distance(np.array(x_train.iloc[j]),i)
      distance = new_manhattan_distance(np.array(x_train.iloc[j]),i)
      distances.append(distance)
    
    # distance_data = pd.DataFrame(data=distances, columns=['Distance List'], index=y_train.index)
    # #print(distance_data)
    # knlst = distance_data.sort_values(by=['Distance List'], axis=0)[:k] 

    # labels = y_train.loc[knlst.index]

    # voting = mode(labels).mode[0]
    voting = votes(distances, y_train, k)
    y_pred.append(voting)

  return y_pred

x_train = train_df.loc[:,'1':'7']
y_train = train_df.loc[:,'label']
x_test = test_df.loc[:,'1':'7']
y_test = test_df.loc[:,'label']

pred = knnclassifier(x_train,x_test,y_train,y_test,3)

print("Predicted value vs actual value")
print("Predicted value:", pred)
print("Actual value:", pred)

